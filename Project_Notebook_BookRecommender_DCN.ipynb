{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67ae282d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moham\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as k\n",
    "import tensorflow_recommenders as tfrs\n",
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import ast\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "import pprint\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d330c398",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Final_Ranker_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75385809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>User_First_Cat</th>\n",
       "      <th>User_Second_Cat</th>\n",
       "      <th>User_Third_Cat</th>\n",
       "      <th>User_Fourth_Cat</th>\n",
       "      <th>Book_First_Cat</th>\n",
       "      <th>Book_Second_Cat</th>\n",
       "      <th>Book_Third_Cat</th>\n",
       "      <th>Book_Fourth_Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>307220</th>\n",
       "      <td>71466</td>\n",
       "      <td>25407</td>\n",
       "      <td>Mystery</td>\n",
       "      <td>Literature</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Crime</td>\n",
       "      <td>Mystery</td>\n",
       "      <td>Noir</td>\n",
       "      <td>Mystery</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605899</th>\n",
       "      <td>127097</td>\n",
       "      <td>11064</td>\n",
       "      <td>Childrens</td>\n",
       "      <td>Picture Books</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Animals</td>\n",
       "      <td>Biography</td>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>European Literature</td>\n",
       "      <td>British Literature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539468</th>\n",
       "      <td>52282</td>\n",
       "      <td>44548</td>\n",
       "      <td>Food and Drink</td>\n",
       "      <td>Childrens</td>\n",
       "      <td>Cookbooks</td>\n",
       "      <td>Cooking</td>\n",
       "      <td>Food and Drink</td>\n",
       "      <td>Cookbooks</td>\n",
       "      <td>Food and Drink</td>\n",
       "      <td>Cooking</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          User   ISBN  User_First_Cat User_Second_Cat User_Third_Cat  \\\n",
       "307220   71466  25407         Mystery      Literature        Fiction   \n",
       "605899  127097  11064       Childrens   Picture Books        Fiction   \n",
       "539468   52282  44548  Food and Drink       Childrens      Cookbooks   \n",
       "\n",
       "       User_Fourth_Cat  Book_First_Cat Book_Second_Cat       Book_Third_Cat  \\\n",
       "307220           Crime         Mystery            Noir              Mystery   \n",
       "605899         Animals       Biography      Nonfiction  European Literature   \n",
       "539468         Cooking  Food and Drink       Cookbooks       Food and Drink   \n",
       "\n",
       "           Book_Fourth_Cat  \n",
       "307220             Fiction  \n",
       "605899  British Literature  \n",
       "539468             Cooking  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)[df.columns[1:]][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18726010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "731"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_genres = []\n",
    "for i in df.columns[3:]:\n",
    "    unique_genres += list(df[f'{i}'].unique() )\n",
    "unique_genres = np.unique(unique_genres)\n",
    "len(unique_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44980614",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = tf.data.Dataset.from_tensor_slices(df.astype('str').values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeb58677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RatingOf5', 'User', 'ISBN', 'User_First_Cat', 'User_Second_Cat',\n",
       "       'User_Third_Cat', 'User_Fourth_Cat', 'Book_First_Cat',\n",
       "       'Book_Second_Cat', 'Book_Third_Cat', 'Book_Fourth_Cat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b2801a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.map(lambda x: {\n",
    "    f\"{df.columns[i]}\": x[i] for i in range(len(df.columns))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33dd17d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup vocab \n",
    "feature_names = df.columns[1:]\n",
    "vocabularies = {}\n",
    "for feature_name in feature_names:\n",
    "    vocab = ratings.batch(1_000_000).map(lambda x: x[feature_name])\n",
    "    vocabularies[feature_name] = np.unique(np.concatenate(list(vocab)))\n",
    "\n",
    "pickle.dump(vocabularies, open('DCN_Recomender_Vocabulary', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94018716",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_features = df.columns[1:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6ca6050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['User',\n",
       " 'ISBN',\n",
       " 'User_First_Cat',\n",
       " 'User_Second_Cat',\n",
       " 'User_Third_Cat',\n",
       " 'User_Fourth_Cat',\n",
       " 'Book_First_Cat',\n",
       " 'Book_Second_Cat',\n",
       " 'Book_Third_Cat',\n",
       " 'Book_Fourth_Cat']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(str_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "1c53c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_tools import DCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "64b2d634",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8*len(ratings))\n",
    "test_size = len(ratings) - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "a5623463",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(train_size)\n",
    "test = shuffled.skip(train_size).take(test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be83ab2a",
   "metadata": {},
   "source": [
    "Prepare train and test data as well as a function to run various models including a embedding + dnn, a dcn with low dimension and another dcn with higher dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "ef77af39",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6ef60803",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabularies = pickle.load(open('DCN_Recomender_Vocabulary', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "0b10551b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(use_cross_layer, deep_layer_sizes, projection_dim=None, num_runs=1):\n",
    "    models = []\n",
    "    rmses = []\n",
    "\n",
    "    for i in range(num_runs):\n",
    "        model = DCN(use_cross_layer=use_cross_layer,\n",
    "                    deep_layer_sizes=deep_layer_sizes,\n",
    "                    projection_dim=projection_dim,\n",
    "                   str_features=str_features,\n",
    "                   vocabularies=vocabularies)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate))\n",
    "        models.append(model)\n",
    "\n",
    "        model.fit(cached_train, epochs=epochs, verbose=False)\n",
    "        metrics = model.evaluate(cached_test, return_dict=True)\n",
    "        rmses.append(metrics[\"RMSE\"])\n",
    "\n",
    "    mean, stdv = np.average(rmses), np.std(rmses)\n",
    "\n",
    "    return {\"model\": models, \"mean\": mean, \"stdv\": stdv}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "cefb09f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "b1f45d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - RMSE: 0.8543 - loss: 0.7288 - regularization_loss: 0.0000e+00 - total_loss: 0.7288\n"
     ]
    }
   ],
   "source": [
    "dcn_result = run_models(use_cross_layer=True,\n",
    "                        deep_layer_sizes=[192, 192])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "1493d8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - RMSE: 0.9724 - loss: 0.9450 - regularization_loss: 0.0000e+00 - total_loss: 0.9450\n"
     ]
    }
   ],
   "source": [
    "dcn_lr_result = run_models(use_cross_layer=True,\n",
    "                           projection_dim=20,\n",
    "                           deep_layer_sizes=[192, 192])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "61cacdeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - RMSE: 0.9401 - loss: 0.8834 - regularization_loss: 0.0000e+00 - total_loss: 0.8834\n"
     ]
    }
   ],
   "source": [
    "dnn_result = run_models(use_cross_layer=False,\n",
    "                        deep_layer_sizes=[192, 192, 192])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "02afc73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCN            RMSE mean: 0.8628, stdv: 0.0000\n",
      "DCN (low-rank) RMSE mean: 0.9724, stdv: 0.0000\n",
      "DNN            RMSE mean: 0.9401, stdv: 0.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"DCN            RMSE mean: {:.4f}, stdv: {:.4f}\".format(\n",
    "    dcn_result[\"mean\"], dcn_result[\"stdv\"]))\n",
    "print(\"DCN (low-rank) RMSE mean: {:.4f}, stdv: {:.4f}\".format(\n",
    "    dcn_lr_result[\"mean\"], dcn_lr_result[\"stdv\"]))\n",
    "print(\"DNN            RMSE mean: {:.4f}, stdv: {:.4f}\".format(\n",
    "    dnn_result[\"mean\"], dnn_result[\"stdv\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd45d5f0",
   "metadata": {},
   "source": [
    "##### Inference\n",
    "\n",
    "I'll take the inference sample to a probability of the user liking the book of choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "377b3404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['The Best American Nonrequired Reading 2003'], dtype=object)"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = df.sample(1)[['User', 'ISBN']].values[0][1]\n",
    "\n",
    "book_title_stringlookup = tf.keras.layers.StringLookup(mask_token=None)\n",
    "book_title_stringlookup.set_weights(np.load(\"ranker_book_titles_vocabulary.npy\", allow_pickle=True))\n",
    "book_id = book_title_stringlookup.call(tf.constant([str(sample)]))\n",
    "\n",
    "le_isbn = joblib.load('ranker_le_isbn')\n",
    "book_title = le_isbn.inverse_transform(book_id)\n",
    "book_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "2ede6922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([97957, 37522, 'Writing', 'Essays', 'Science', 'Environment',\n",
       "       'Fiction', 'Anthologies', 'Short Stories', 'Literature'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I'll see the probability of the following sampled user being interested in the sample book above\n",
    "user_arr = df[df.User == int(df.sample(1)['User'])].values[0]\n",
    "book_arr = df[df.ISBN == book_id].values[0]\n",
    "for i in [1,3,4,5,6]:\n",
    "    book_arr[i:i+1] = user_arr[i]\n",
    "book_arr[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "ae5eb5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_arr = tf.data.Dataset.from_tensor_slices(book_arr.astype('str').reshape(1,-1))\n",
    "inference_sample = book_arr.map(lambda x: {\n",
    "    f\"{df.columns[i]}\": x[i] for i in range(len(df.columns))})\n",
    "for inference_sample in inference_sample.take(1):\n",
    "    break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "86388ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[3.0650332]], dtype=float32)>"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcn_result['model'][0].call(inference_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "4b772d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[4.4947515]], dtype=float32)>"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcn_lr_result['model'][0].call(inference_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "e5246ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[4.065869]], dtype=float32)>"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_result['model'][0].call(inference_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f3b874",
   "metadata": {},
   "source": [
    "- The logits may surpass the actual rating of 5 since this was a continuous value prediction task and not a classification task.\n",
    "- The relative value of logits among the models will tell us how accurate the model is. The higher the logit the more likely the model assumers that the user will like the book\n",
    "- In the above example, *the higher rank DCN is better able to capture teh divergence of the user's preferences ['Writing', 'Essays', 'Science', 'Environment'] vs. those of the book of interest ['Fiction', 'Anthologies', 'Short Stories', 'Literature'] which constrast quite a bit*. The **dcn (high rank) model was able to capture this with a lower logit prediction than those of the dcn_lr and dnn meaning the user is unlikely to be interested in this book** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
